{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:02:07.204634Z",
     "start_time": "2022-01-16T11:02:07.046148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:02:08.770864Z",
     "start_time": "2022-01-16T11:02:08.755889Z"
    }
   },
   "outputs": [],
   "source": [
    "DATAPATH = r\"C:\\Users\\yuvfr\\proj_university\\swedish-leaf-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:42:45.794638Z",
     "start_time": "2022-01-16T12:42:45.781660Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image(filename, height=224, width=224):\n",
    "    img = cv.imread(filename, cv.IMREAD_COLOR)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img = cv.resize(img, (height, width))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:10:34.100458Z",
     "start_time": "2022-01-16T12:10:24.515787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load leaf1\n",
      "(2508, 1423, 3)\n",
      "(2143, 1147, 3)\n",
      "(1994, 1294, 3)\n",
      "(2482, 1457, 3)\n",
      "(1580, 917, 3)\n",
      "(1154, 779, 3)\n",
      "(1304, 791, 3)\n",
      "(1379, 804, 3)\n",
      "(2207, 1508, 3)\n",
      "(1705, 1080, 3)\n",
      "(1718, 1068, 3)\n",
      "(2207, 1106, 3)\n",
      "(1303, 1118, 3)\n",
      "(1579, 930, 3)\n",
      "(1793, 1030, 3)\n",
      "(1379, 867, 3)\n",
      "(1618, 1005, 3)\n",
      "(1842, 1206, 3)\n",
      "(2131, 1206, 3)\n",
      "(2156, 1194, 3)\n",
      "(1379, 1018, 3)\n",
      "(1191, 879, 3)\n",
      "(2045, 1046, 3)\n",
      "(2094, 1235, 3)\n",
      "(1843, 1131, 3)\n",
      "(1404, 841, 3)\n",
      "(2031, 1272, 3)\n",
      "(2018, 1193, 3)\n",
      "(1655, 1005, 3)\n",
      "(1530, 880, 3)\n",
      "(1580, 1017, 3)\n",
      "(2231, 1306, 3)\n",
      "(1505, 867, 3)\n",
      "(1818, 1105, 3)\n",
      "(1204, 729, 3)\n",
      "(1104, 753, 3)\n",
      "(1743, 1219, 3)\n",
      "(2043, 1457, 3)\n",
      "(2144, 1419, 3)\n",
      "(1981, 1244, 3)\n",
      "(2533, 1420, 3)\n",
      "(1981, 1035, 3)\n",
      "(1680, 1118, 3)\n",
      "(2044, 1193, 3)\n",
      "(1129, 754, 3)\n",
      "(1379, 841, 3)\n",
      "(2093, 1194, 3)\n",
      "(1216, 791, 3)\n",
      "(2144, 1269, 3)\n",
      "(1279, 833, 3)\n",
      "(1768, 1180, 3)\n",
      "(1818, 1206, 3)\n",
      "(1530, 967, 3)\n",
      "(1204, 734, 3)\n",
      "(1229, 854, 3)\n",
      "(1078, 792, 3)\n",
      "(2257, 1322, 3)\n",
      "(917, 609, 3)\n",
      "(1455, 921, 3)\n",
      "(1706, 1035, 3)\n",
      "(1431, 1013, 3)\n",
      "(1592, 1146, 3)\n",
      "(2120, 1197, 3)\n",
      "(1707, 1110, 3)\n",
      "(1780, 1005, 3)\n",
      "(1431, 783, 3)\n",
      "(1141, 779, 3)\n",
      "(1280, 820, 3)\n",
      "(1819, 1033, 3)\n",
      "(1605, 1005, 3)\n",
      "(1480, 988, 3)\n",
      "(1067, 733, 3)\n",
      "(1469, 985, 3)\n",
      "(1643, 984, 3)\n",
      "(1231, 808, 3)\n",
      "75 images \n",
      "\n",
      "load leaf2\n",
      "(2469, 1557, 3)\n",
      "(3848, 2550, 3)\n",
      "(2947, 2374, 3)\n",
      "(2445, 1721, 3)\n",
      "(3987, 2324, 3)\n",
      "(3598, 2160, 3)\n",
      "(2056, 1307, 3)\n",
      "(1994, 1558, 3)\n",
      "(2909, 1771, 3)\n",
      "(2457, 1658, 3)\n",
      "(2345, 1721, 3)\n",
      "(3172, 2098, 3)\n",
      "(3184, 1985, 3)\n",
      "(3046, 2186, 3)\n",
      "(3823, 2311, 3)\n",
      "(3461, 1960, 3)\n",
      "(2795, 1997, 3)\n",
      "(3475, 1897, 3)\n",
      "(4125, 2412, 3)\n",
      "(3147, 2123, 3)\n",
      "(2608, 1985, 3)\n",
      "(3335, 2411, 3)\n",
      "(3021, 1847, 3)\n",
      "(2232, 1382, 3)\n",
      "(2370, 1897, 3)\n",
      "(3235, 2160, 3)\n",
      "(2645, 2299, 3)\n",
      "(1943, 1318, 3)\n",
      "(2006, 1759, 3)\n",
      "(3398, 2287, 3)\n",
      "(2871, 1671, 3)\n",
      "(3949, 2425, 3)\n",
      "(3285, 2211, 3)\n",
      "(2934, 2073, 3)\n",
      "(3536, 2487, 3)\n",
      "(2370, 2022, 3)\n",
      "(2332, 1998, 3)\n",
      "(2332, 2047, 3)\n",
      "(2771, 2349, 3)\n",
      "(3034, 2035, 3)\n",
      "(3122, 2148, 3)\n",
      "(3447, 2273, 3)\n",
      "(3624, 2161, 3)\n",
      "(3749, 2450, 3)\n",
      "(2996, 2198, 3)\n",
      "(2658, 2512, 3)\n",
      "(1705, 1495, 3)\n",
      "(3184, 2249, 3)\n",
      "(2081, 1658, 3)\n",
      "(3235, 2098, 3)\n",
      "(1855, 1708, 3)\n",
      "(3122, 1985, 3)\n",
      "(2232, 1834, 3)\n",
      "(3824, 2475, 3)\n",
      "(3072, 2035, 3)\n",
      "(2632, 1859, 3)\n",
      "(2206, 1721, 3)\n",
      "(3423, 2210, 3)\n",
      "(2395, 1683, 3)\n",
      "(2883, 1972, 3)\n",
      "(1755, 1331, 3)\n",
      "(2307, 1784, 3)\n",
      "(2570, 2110, 3)\n",
      "(2821, 2425, 3)\n",
      "(2558, 2073, 3)\n",
      "(2846, 1797, 3)\n",
      "(2169, 1357, 3)\n",
      "(2821, 1658, 3)\n",
      "(2871, 1922, 3)\n",
      "(3936, 2236, 3)\n",
      "(2796, 2110, 3)\n",
      "(2332, 2160, 3)\n",
      "(2758, 1846, 3)\n",
      "(3686, 2287, 3)\n",
      "(2746, 1683, 3)\n",
      "75 images \n",
      "\n",
      "load leaf3\n",
      "(2018, 992, 3)\n",
      "(2307, 1307, 3)\n",
      "(2006, 1093, 3)\n",
      "(1756, 842, 3)\n",
      "(1743, 921, 3)\n",
      "(2031, 1260, 3)\n",
      "(1717, 1030, 3)\n",
      "(1680, 1018, 3)\n",
      "(1655, 854, 3)\n",
      "(1667, 942, 3)\n",
      "(1968, 942, 3)\n",
      "(1768, 867, 3)\n",
      "(1956, 1158, 3)\n",
      "(2144, 1080, 3)\n",
      "(1856, 1118, 3)\n",
      "(1918, 1080, 3)\n",
      "(1705, 1093, 3)\n",
      "(2156, 1042, 3)\n",
      "(2043, 955, 3)\n",
      "(1905, 1092, 3)\n",
      "(1993, 1030, 3)\n",
      "(1818, 1042, 3)\n",
      "(1930, 971, 3)\n",
      "(1868, 1046, 3)\n",
      "(1730, 905, 3)\n",
      "(1956, 892, 3)\n",
      "(1705, 1005, 3)\n",
      "(1555, 1025, 3)\n",
      "(2031, 1105, 3)\n",
      "(1925, 1172, 3)\n",
      "(2019, 1105, 3)\n",
      "(1505, 904, 3)\n",
      "(1793, 980, 3)\n",
      "(1718, 1050, 3)\n",
      "(1893, 1180, 3)\n",
      "(1981, 1181, 3)\n",
      "(1806, 1042, 3)\n",
      "(1631, 885, 3)\n",
      "(1530, 855, 3)\n",
      "(1756, 993, 3)\n",
      "(1857, 1013, 3)\n",
      "(1881, 1080, 3)\n",
      "(1919, 1075, 3)\n",
      "(1681, 963, 3)\n",
      "(2006, 1172, 3)\n",
      "(1292, 741, 3)\n",
      "(1217, 896, 3)\n",
      "(1694, 1021, 3)\n",
      "(1605, 1095, 3)\n",
      "(1780, 1047, 3)\n",
      "(1668, 1060, 3)\n",
      "(1956, 1256, 3)\n",
      "(1755, 1106, 3)\n",
      "(1956, 975, 3)\n",
      "(1717, 779, 3)\n",
      "(1605, 988, 3)\n",
      "(1363, 925, 3)\n",
      "(1517, 892, 3)\n",
      "(1793, 892, 3)\n",
      "(1655, 854, 3)\n",
      "(1780, 1093, 3)\n",
      "(1968, 980, 3)\n",
      "(1555, 929, 3)\n",
      "(1430, 955, 3)\n",
      "(1907, 1075, 3)\n",
      "(1480, 921, 3)\n",
      "(1818, 892, 3)\n",
      "(1856, 938, 3)\n",
      "(1681, 1000, 3)\n",
      "(2019, 1085, 3)\n",
      "(1655, 955, 3)\n",
      "(1555, 855, 3)\n",
      "(1454, 791, 3)\n",
      "(1730, 892, 3)\n",
      "(1906, 1125, 3)\n",
      "75 images \n",
      "\n",
      "load leaf4\n",
      "(1153, 741, 3)\n",
      "(1542, 930, 3)\n",
      "(1354, 716, 3)\n",
      "(1793, 979, 3)\n",
      "(1317, 804, 3)\n",
      "(1267, 754, 3)\n",
      "(1204, 729, 3)\n",
      "(1129, 716, 3)\n",
      "(1442, 867, 3)\n",
      "(1767, 980, 3)\n",
      "(1743, 1042, 3)\n",
      "(1405, 1017, 3)\n",
      "(1554, 992, 3)\n",
      "(1116, 616, 3)\n",
      "(1241, 779, 3)\n",
      "(1429, 842, 3)\n",
      "(1504, 904, 3)\n",
      "(1479, 1018, 3)\n",
      "(1479, 904, 3)\n",
      "(1040, 628, 3)\n",
      "(1266, 691, 3)\n",
      "(1291, 766, 3)\n",
      "(1003, 666, 3)\n",
      "(1266, 704, 3)\n",
      "(1204, 666, 3)\n",
      "(1040, 653, 3)\n",
      "(1405, 1096, 3)\n",
      "(1342, 779, 3)\n",
      "(1329, 678, 3)\n",
      "(1229, 716, 3)\n",
      "(990, 590, 3)\n",
      "(1605, 979, 3)\n",
      "(1304, 792, 3)\n",
      "(1392, 892, 3)\n",
      "(1203, 829, 3)\n",
      "(1304, 842, 3)\n",
      "(1567, 1030, 3)\n",
      "(1680, 892, 3)\n",
      "(1404, 917, 3)\n",
      "(1317, 892, 3)\n",
      "(1416, 804, 3)\n",
      "(1517, 879, 3)\n",
      "(1630, 829, 3)\n",
      "(1755, 929, 3)\n",
      "(1366, 653, 3)\n",
      "(1643, 904, 3)\n",
      "(1554, 992, 3)\n",
      "(1529, 904, 3)\n",
      "(1442, 905, 3)\n",
      "(1405, 1009, 3)\n",
      "(1328, 879, 3)\n",
      "(1517, 892, 3)\n",
      "(1316, 778, 3)\n",
      "(1316, 729, 3)\n",
      "(1580, 930, 3)\n",
      "(1341, 753, 3)\n",
      "(1191, 691, 3)\n",
      "(1304, 804, 3)\n",
      "(1655, 866, 3)\n",
      "(1593, 1042, 3)\n",
      "(1356, 963, 3)\n",
      "(1341, 778, 3)\n",
      "(1642, 942, 3)\n",
      "(1180, 746, 3)\n",
      "(1368, 683, 3)\n",
      "(1256, 822, 3)\n",
      "(1217, 1021, 3)\n",
      "(1181, 772, 3)\n",
      "(1192, 813, 3)\n",
      "(1192, 779, 3)\n",
      "(1618, 1021, 3)\n",
      "(1380, 746, 3)\n",
      "(1230, 695, 3)\n",
      "(1255, 758, 3)\n",
      "(1417, 846, 3)\n",
      "75 images \n",
      "\n",
      "load leaf5\n",
      "(1206, 697, 3)\n",
      "(840, 490, 3)\n",
      "(865, 515, 3)\n",
      "(815, 490, 3)\n",
      "(1041, 540, 3)\n",
      "(1015, 653, 3)\n",
      "(1003, 603, 3)\n",
      "(1166, 716, 3)\n",
      "(1430, 888, 3)\n",
      "(890, 465, 3)\n",
      "(990, 628, 3)\n",
      "(1242, 691, 3)\n",
      "(1041, 582, 3)\n",
      "(928, 553, 3)\n",
      "(1229, 729, 3)\n",
      "(1028, 666, 3)\n",
      "(1129, 641, 3)\n",
      "(953, 490, 3)\n",
      "(1230, 671, 3)\n",
      "(1053, 591, 3)\n",
      "(1041, 565, 3)\n",
      "(1192, 698, 3)\n",
      "(852, 503, 3)\n",
      "(1053, 565, 3)\n",
      "(1003, 528, 3)\n",
      "(1078, 603, 3)\n",
      "(1015, 490, 3)\n",
      "(1003, 603, 3)\n",
      "(890, 477, 3)\n",
      "(828, 402, 3)\n",
      "(702, 465, 3)\n",
      "(690, 440, 3)\n",
      "(1078, 590, 3)\n",
      "(1103, 716, 3)\n",
      "(927, 477, 3)\n",
      "(1103, 641, 3)\n",
      "(928, 528, 3)\n",
      "(1104, 616, 3)\n",
      "(652, 465, 3)\n",
      "(953, 541, 3)\n",
      "(940, 603, 3)\n",
      "(928, 515, 3)\n",
      "(1015, 577, 3)\n",
      "(991, 578, 3)\n",
      "(965, 578, 3)\n",
      "(915, 515, 3)\n",
      "(890, 540, 3)\n",
      "(792, 691, 3)\n",
      "(890, 515, 3)\n",
      "(940, 528, 3)\n",
      "(902, 553, 3)\n",
      "(1003, 578, 3)\n",
      "(902, 503, 3)\n",
      "(953, 565, 3)\n",
      "(1040, 591, 3)\n",
      "(1116, 729, 3)\n",
      "(1066, 666, 3)\n",
      "(1078, 666, 3)\n",
      "(1028, 553, 3)\n",
      "(1116, 691, 3)\n",
      "(991, 616, 3)\n",
      "(1078, 679, 3)\n",
      "(1028, 628, 3)\n",
      "(953, 527, 3)\n",
      "(827, 528, 3)\n",
      "(952, 540, 3)\n",
      "(1016, 603, 3)\n",
      "(727, 515, 3)\n",
      "(1103, 690, 3)\n",
      "(915, 515, 3)\n",
      "(940, 566, 3)\n",
      "(1191, 753, 3)\n",
      "(1003, 653, 3)\n",
      "(790, 540, 3)\n",
      "(903, 452, 3)\n",
      "75 images \n",
      "\n",
      "load leaf6\n",
      "(1466, 992, 3)\n",
      "(1718, 1042, 3)\n",
      "(1316, 980, 3)\n",
      "(764, 653, 3)\n",
      "(1053, 904, 3)\n",
      "(1341, 891, 3)\n",
      "(1793, 1143, 3)\n",
      "(1179, 829, 3)\n",
      "(1154, 942, 3)\n",
      "(1692, 892, 3)\n",
      "(1956, 1156, 3)\n",
      "(1141, 929, 3)\n",
      "(1629, 929, 3)\n",
      "(1780, 1042, 3)\n",
      "(878, 778, 3)\n",
      "(1128, 829, 3)\n",
      "(1066, 892, 3)\n",
      "(1291, 867, 3)\n",
      "(1993, 1244, 3)\n",
      "(878, 678, 3)\n",
      "(1743, 1143, 3)\n",
      "(1730, 1030, 3)\n",
      "(1379, 917, 3)\n",
      "(902, 654, 3)\n",
      "(1504, 1118, 3)\n",
      "(1880, 1156, 3)\n",
      "(1054, 729, 3)\n",
      "(1717, 1218, 3)\n",
      "(1994, 1218, 3)\n",
      "(1542, 1244, 3)\n",
      "(2219, 1382, 3)\n",
      "(1843, 1030, 3)\n",
      "(840, 678, 3)\n",
      "(1279, 1055, 3)\n",
      "(1128, 829, 3)\n",
      "(1542, 1093, 3)\n",
      "(2031, 1219, 3)\n",
      "(1041, 855, 3)\n",
      "(2069, 1269, 3)\n",
      "(1730, 1256, 3)\n",
      "(1341, 942, 3)\n",
      "(1868, 1206, 3)\n",
      "(1178, 1030, 3)\n",
      "(1392, 942, 3)\n",
      "(1430, 1043, 3)\n",
      "(1580, 1219, 3)\n",
      "(1492, 854, 3)\n",
      "(1517, 1017, 3)\n",
      "(1053, 842, 3)\n",
      "(2057, 1306, 3)\n",
      "(1454, 891, 3)\n",
      "(1956, 1256, 3)\n",
      "(1492, 955, 3)\n",
      "(1894, 1243, 3)\n",
      "(1981, 1331, 3)\n",
      "(1868, 1332, 3)\n",
      "(1354, 1068, 3)\n",
      "(1429, 995, 3)\n",
      "(1417, 993, 3)\n",
      "(1931, 1156, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-4a1bc0054dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg_fname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mleaf_imgs_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-4a1bc0054dc6>\u001b[0m in \u001b[0;36mload_image\u001b[1;34m(filename, height, width)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "classes = [f'leaf{i}' for i in range(1,16)]\n",
    "\n",
    "for i, leaf in enumerate(classes):\n",
    "    \n",
    "    leaf_path = os.path.join(DATAPATH,leaf)\n",
    "    print(f\"load {leaf}\")\n",
    "    leaf_imgs_list = []\n",
    "    \n",
    "    for img_fname in os.listdir(leaf_path):\n",
    "        leaf_imgs_list.append(load_image(os.path.join(leaf_path, img_fname)))\n",
    "            \n",
    "            \n",
    "    data_dict[leaf] = {'data':np.stack(leaf_imgs_list), 'label':np.repeat(i, len(leaf_imgs_list)).reshape(-1,1)}\n",
    "    \n",
    "    print(f\"{len(leaf_imgs_list)} images\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:03:23.132406Z",
     "start_time": "2022-01-16T11:03:23.015414Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.vstack([data_dict[k]['data'] for k in data_dict.keys()])\n",
    "labels = np.repeat(np.arange(1,16), 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:03:50.996634Z",
     "start_time": "2022-01-16T11:03:50.991637Z"
    }
   },
   "outputs": [],
   "source": [
    "pretrain_preprocess = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:37:51.863743Z",
     "start_time": "2022-01-16T12:37:51.852743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for PyTorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T12:51:15.254404Z",
     "start_time": "2022-01-16T12:51:15.247409Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     ZeroOneScale(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T13:29:33.122302Z",
     "start_time": "2022-01-16T13:29:33.107300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, main_dir, loader, transform, label):\n",
    "        self.main_dir = main_dir\n",
    "        self.img_list = os.listdir(main_dir)\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.img_list[idx])\n",
    "        image = self.loader(img_loc)\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image, self.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T13:28:03.315933Z",
     "start_time": "2022-01-16T13:28:03.293937Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_leaf_datasets(datasets, test_perc):\n",
    "    splits = [torch.utils.data.random_split(\n",
    "        data, lengths=(\n",
    "            int(len(data)*(1-test_perc)), int(len(data)*test_perc) + 1)) \n",
    "              for data in datasets]\n",
    "    \n",
    "    train = torch.utils.data.ConcatDataset([split[0] for split in splits])\n",
    "    valid = torch.utils.data.ConcatDataset([split[1] for split in splits])\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T19:52:03.782784Z",
     "start_time": "2022-01-16T19:52:03.769780Z"
    }
   },
   "outputs": [],
   "source": [
    "leaf9_ds = LeafDataset(os.path.join(DATAPATH, 'leaf9'), load_image, preprocess, 9)\n",
    "leaf10_ds = LeafDataset(os.path.join(DATAPATH, 'leaf10'), load_image, preprocess, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T13:22:57.293537Z",
     "start_time": "2022-01-16T13:22:57.284526Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid = split_leaf_datasets([leaf9_ds,leaf10_ds], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T13:30:34.247426Z",
     "start_time": "2022-01-16T13:30:34.239404Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=4)\n",
    "valid_loader = DataLoader(valid, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T14:41:07.052440Z",
     "start_time": "2022-01-16T14:41:07.044445Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetTransfer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True).to(device)\n",
    "        resnet_fc_in_features = self.resnet.fc.in_features\n",
    "        self.remove_resnet_fc_layer()\n",
    "        self.resnet.eval()  # to be not optimized and use all neurons w/o dropout/batchnorm etc..\n",
    "        self.fc = torch.nn.Linear(resnet_fc_in_features, 2).to(device)\n",
    "\n",
    "    def remove_resnet_fc_layer(self):\n",
    "        class IdentityLayer(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "\n",
    "            def forward(self, x):\n",
    "                return x\n",
    "\n",
    "        self.resnet.fc = IdentityLayer()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.resnet(x)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T14:41:07.259146Z",
     "start_time": "2022-01-16T14:41:07.242147Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import copy\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, criterion, optimizer, num_epochs=25):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    def make_epoch(self, dataloader, train=True):\n",
    "        running_num_examples = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        with torch.set_grad_enabled(train):\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                if train:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                # statistics\n",
    "                running_num_examples += inputs.shape[0]\n",
    "                running_loss += loss.item() * inputs.shape[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / running_num_examples\n",
    "        epoch_acc = float(running_corrects) / running_num_examples\n",
    "        self.print_epoch_stats(epoch_loss, epoch_acc)\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def print_epoch_stats(epoch_loss, epoch_acc, train=True):\n",
    "        print(f'{\"train\" if train else \"valid\"} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    def train(self, train_loader, val_loader):\n",
    "        start = time()\n",
    "        best_model_weights = copy.deepcopy(self.model.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "            \n",
    "            self.model.train()\n",
    "            train_loss, train_acc = self.make_epoch(train_loader, train=True)\n",
    "            self.model.eval()\n",
    "            val_loss, val_acc = self.make_epoch(val_loader, train=False)\n",
    "\n",
    "            # deep copy the model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model_weights = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        time_elapsed = time() - start\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print('Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        self.model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T14:41:07.830142Z",
     "start_time": "2022-01-16T14:41:07.435148Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_transfer = ResNetTransfer()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet_transfer.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(resnet_transfer, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T19:51:08.501707Z",
     "start_time": "2022-01-16T19:51:08.445706Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetTransfer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, fine_tune=True):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True).to(device)\n",
    "        resnet_fc_in_features = self.resnet.fc.in_features\n",
    "        self.remove_resnet_fc_layer()\n",
    "        self.fc = torch.nn.Linear(resnet_fc_in_features, 2).to(device)\n",
    "        if not fine_tune:\n",
    "            self.freeze_base_model()\n",
    "        self.fine_tune = fine_tune\n",
    "\n",
    "    def remove_resnet_fc_layer(self):\n",
    "        class IdentityLayer(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "\n",
    "            def forward(self, x):\n",
    "                return x\n",
    "\n",
    "        self.resnet.fc = IdentityLayer()\n",
    "\n",
    "    def freeze_base_model(self):\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet.eval()  # to be not optimized and use all neurons w/o dropout/batchnorm etc..\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(self.fine_tune):\n",
    "            features = self.resnet(x)\n",
    "        out = self.fc(features)\n",
    "        # out = torch.argmax(fc_out, 1).double().view(-1, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:10:47.870611Z",
     "start_time": "2022-01-16T20:10:47.336593Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetTransfer(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): IdentityLayer()\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetTransfer()\n",
    "model.load_state_dict(torch.load(os.path.join(DATAPATH, \"model.pt\")))\n",
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:10:54.623819Z",
     "start_time": "2022-01-16T20:10:53.863828Z"
    }
   },
   "outputs": [],
   "source": [
    "test9 = torch.stack([leaf9_ds[i][0] for i in range(10)])\n",
    "test10 = torch.stack([leaf10_ds[i][0] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:11:22.645046Z",
     "start_time": "2022-01-16T20:11:22.034050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3372, -0.7167],\n",
       "        [-0.0251, -0.7810],\n",
       "        [ 0.1681, -0.6588],\n",
       "        [-0.5023, -1.3448],\n",
       "        [-0.1434, -0.9854],\n",
       "        [ 0.0537, -1.2923],\n",
       "        [ 0.0589, -0.6024],\n",
       "        [-0.1913, -0.4254],\n",
       "        [-0.0597, -0.9748],\n",
       "        [-0.1912, -0.8173]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(test9)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:11:29.610612Z",
     "start_time": "2022-01-16T20:11:29.598604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:11:52.522206Z",
     "start_time": "2022-01-16T20:11:51.894229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1114,  0.8221],\n",
       "        [-1.0072,  0.8887],\n",
       "        [-1.0156,  0.9057],\n",
       "        [-1.6461,  0.0758],\n",
       "        [-1.7470,  0.3160],\n",
       "        [-1.8434,  0.5084],\n",
       "        [-1.3324,  0.7622],\n",
       "        [-0.4403,  1.4134],\n",
       "        [-1.0851,  0.5680],\n",
       "        [-1.3497,  0.6165]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out10 = model(test10)\n",
    "out10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T20:12:02.835932Z",
     "start_time": "2022-01-16T20:12:02.828947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T16:38:26.927535Z",
     "start_time": "2022-01-16T16:38:26.908537Z"
    }
   },
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(128,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T16:38:37.116367Z",
     "start_time": "2022-01-16T16:38:37.107378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(lin, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-16T11:21:36.163823Z",
     "start_time": "2022-01-16T11:21:36.144829Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in transfer_resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
